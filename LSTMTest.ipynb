{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/karthik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndf2 = pd.read_table(\\'glove.twitter.27B.25d.txt\\', sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\\n\\ndef vectorize(w):\\n  return df2.loc[w].as_matrix()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import nltk \n",
    "\n",
    "import gensim as gs\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "df1 = pd.read_csv('HillaryTrumpTrainWithTags.csv')\n",
    "df2 = pd.read_csv('TrumpHillaryTest.csv')\n",
    "\"\"\"\n",
    "df2 = pd.read_table('glove.twitter.27B.25d.txt', sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "def vectorize(w):\n",
    "  return df2.loc[w].as_matrix()\n",
    "\"\"\"\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handleToNumber(handle):\n",
    "    if handle == \"realDonaldTrump\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tokenized_tweets'] = df1.apply(lambda row: nltk.word_tokenize(row['tweet']), axis=1)\n",
    "df1['labels'] = df1.apply(lambda row: handleToNumber(row['handle']), axis=1)\n",
    "df2['tokenized_tweets'] = df2.apply(lambda row: nltk.word_tokenize(row['tweet']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df1['tokenized_tweets']\n",
    "tweets_test = df2['tokenized_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "_ = df1.apply(lambda row: length.append(len(row['tokenized_tweets'])), axis=1)\n",
    "max_length = max(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = gs.models.Word2Vec(df1['tokenized_tweets'].append(df2['tokenized_tweets']) , min_count=1, size = 25, iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = []\n",
    "\n",
    "for i, tweet in enumerate(tweets):\n",
    "    #print(type(string))\n",
    "    train_matrix.append(vectorizer.wv[tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(train_matrix).reshape(len(train_matrix),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.06081116e-01, -2.19484344e-01, -3.88274312e-01,\n",
       "        -1.61107138e-01, -1.00259507e+00,  3.27443928e-01,\n",
       "        -1.11286491e-01, -6.41066313e-01,  1.22273910e+00,\n",
       "         1.51146317e+00,  5.44606924e-01,  8.63679528e-01,\n",
       "         1.99143612e+00,  6.36692703e-01,  6.16807878e-01,\n",
       "         2.18709469e-01,  2.33206689e-01, -6.15914166e-01,\n",
       "         9.98988688e-01, -7.40315318e-01, -1.08086300e+00,\n",
       "         5.99119104e-02,  1.49287045e+00,  7.63807058e-01,\n",
       "        -8.84026170e-01],\n",
       "       [-2.07941487e-01,  2.03470401e-02,  2.27209833e-02,\n",
       "         2.17259526e-01, -3.01008165e-01,  1.78454652e-01,\n",
       "        -1.20773606e-01, -2.59526819e-02,  4.34588730e-01,\n",
       "         2.96456426e-01,  4.70216304e-01, -7.75579438e-02,\n",
       "         5.98252773e-01, -1.21941613e-02,  2.69649953e-01,\n",
       "        -1.87879547e-01, -1.22828498e-01, -1.45573393e-01,\n",
       "         6.30454421e-01, -2.89097577e-01, -5.18052578e-01,\n",
       "         4.21677500e-01,  5.24195910e-01,  2.36306012e-01,\n",
       "        -4.38531160e-01],\n",
       "       [-5.37931204e-01, -1.15740681e+00, -2.62848854e-01,\n",
       "         5.55605292e-01, -1.10466778e+00,  2.24988550e-01,\n",
       "         1.05419123e+00, -1.73730820e-01,  2.24177861e+00,\n",
       "         1.71817422e+00,  2.06091285e-01,  1.19896376e+00,\n",
       "         1.48356879e+00,  8.09530795e-01,  2.50506115e+00,\n",
       "         1.01956964e+00,  1.14684761e+00, -2.12621379e+00,\n",
       "         2.12685156e+00, -1.32381618e+00, -4.76170808e-01,\n",
       "        -9.54487681e-01,  2.46699262e+00,  3.47111881e-01,\n",
       "         3.58097881e-01],\n",
       "       [-8.27185586e-02, -7.92076439e-02,  6.36644429e-03,\n",
       "         9.58568901e-02, -1.34378716e-01,  1.43278733e-01,\n",
       "        -1.87867600e-02,  1.30211851e-02,  2.80500889e-01,\n",
       "         7.45622069e-02,  1.64608836e-01,  4.99794967e-02,\n",
       "         2.54910618e-01,  2.94661466e-02,  1.86477169e-01,\n",
       "        -7.03015253e-02,  1.26146208e-02, -9.38988328e-02,\n",
       "         2.65497804e-01, -1.13711722e-01, -1.51007310e-01,\n",
       "         8.11488405e-02,  2.66648710e-01,  4.05077413e-02,\n",
       "        -1.57100603e-01],\n",
       "       [-4.36937332e-01,  2.68675257e-02, -4.35088992e-01,\n",
       "        -5.79150081e-01, -2.80289173e-01,  8.80806208e-01,\n",
       "         1.76184073e-01,  6.97001159e-01,  8.14910293e-01,\n",
       "        -3.95677239e-01,  3.77561897e-03, -2.67833322e-01,\n",
       "         1.44710207e+00,  3.52690220e-01,  5.25094748e-01,\n",
       "         4.33800332e-02,  5.26738346e-01, -6.37387335e-01,\n",
       "         1.29518378e+00, -6.26045048e-01, -5.06870568e-01,\n",
       "         7.68993616e-01,  1.34563863e+00,  5.89811623e-01,\n",
       "        -4.98214215e-01],\n",
       "       [-5.62701166e-01, -2.63645673e+00, -3.05882931e+00,\n",
       "         2.10254502e+00, -4.08563280e+00,  3.48978281e+00,\n",
       "        -7.39529908e-01,  1.92412090e+00,  4.34229851e-01,\n",
       "         2.87572742e-01,  1.34864819e+00, -4.92053956e-01,\n",
       "         3.09904432e+00, -1.01675510e-01,  2.69896579e+00,\n",
       "        -2.06672740e+00,  2.45392919e+00,  2.75110424e-01,\n",
       "         3.45909834e+00, -1.67749536e+00,  4.36078757e-03,\n",
       "        -1.81406415e+00,  2.29093027e+00, -2.02891517e+00,\n",
       "        -9.15194750e-02],\n",
       "       [-8.50235343e-01, -6.23635590e-01, -2.01709062e-01,\n",
       "         1.76089382e+00, -3.51973081e+00,  5.72052412e-02,\n",
       "         7.20117316e-02,  1.12165928e+00,  2.07743526e+00,\n",
       "         3.37892795e+00, -6.54675305e-01,  1.01383054e+00,\n",
       "         2.79722929e+00, -9.66792703e-01,  1.52095807e+00,\n",
       "         7.80914500e-02,  7.39204586e-01, -5.95151305e-01,\n",
       "         1.65194285e+00,  1.01768804e+00,  7.54443049e-01,\n",
       "        -1.65456486e+00,  3.56370211e+00, -5.51098466e-01,\n",
       "         1.67405874e-01],\n",
       "       [ 6.51263595e-01,  2.74083048e-01,  2.71163718e-03,\n",
       "         1.98303950e+00, -2.86710286e+00,  1.38993788e+00,\n",
       "         1.86092830e+00,  1.46930599e+00,  2.23991632e+00,\n",
       "         1.35098767e+00,  3.89280617e-02,  8.30292761e-01,\n",
       "         3.27611613e+00, -1.12592673e+00,  1.54289258e+00,\n",
       "         1.76697528e+00,  1.51776350e+00, -1.80012524e-01,\n",
       "         2.49221158e+00, -1.13112199e+00, -5.16871810e-01,\n",
       "        -1.56539083e+00,  3.22134805e+00, -6.21529698e-01,\n",
       "        -3.67301404e-01],\n",
       "       [-2.67305434e-01,  1.59942746e+00,  1.11172950e+00,\n",
       "         1.04470515e+00, -1.61826766e+00, -8.25125277e-01,\n",
       "         2.23021317e+00, -3.26387435e-01,  3.19798827e+00,\n",
       "         3.30337811e+00,  8.52415860e-01,  9.98920381e-01,\n",
       "         2.19769430e+00, -3.02170515e-01,  1.35323656e+00,\n",
       "         2.40248847e+00, -5.27553439e-01, -8.81390989e-01,\n",
       "         1.55280066e+00, -8.74781609e-01,  4.61194694e-01,\n",
       "        -1.94652840e-01,  3.09523582e+00, -3.94046046e-02,\n",
       "        -9.76619959e-01],\n",
       "       [ 7.66773999e-01, -4.97517698e-02,  7.32319772e-01,\n",
       "         3.43862915e+00, -3.27821112e+00, -4.34855409e-02,\n",
       "         1.39204144e+00,  1.35426605e+00,  1.72104836e+00,\n",
       "         3.15025163e+00,  2.27509916e-01,  9.08288181e-01,\n",
       "         2.31215167e+00, -2.42488766e+00,  2.55475831e+00,\n",
       "         3.37095588e-01, -2.41067093e-02,  1.14228928e+00,\n",
       "         3.06268954e+00,  5.36207736e-01, -9.99400973e-01,\n",
       "        -2.04667854e+00,  2.57187986e+00,  4.45661038e-01,\n",
       "        -1.22298372e+00],\n",
       "       [ 1.51275709e-01, -5.28182797e-02, -1.25713851e-02,\n",
       "         8.06392133e-02, -2.39527300e-01, -1.69984251e-02,\n",
       "         1.64314017e-01,  3.07483431e-02,  7.92164952e-02,\n",
       "         4.42389660e-02, -1.57301128e-01,  1.03118405e-01,\n",
       "         1.60567209e-01, -7.88750574e-02,  1.00701429e-01,\n",
       "        -1.05429120e-01,  1.30457282e-01,  8.68177041e-02,\n",
       "        -6.75083138e-03,  5.15279844e-02,  1.80058494e-01,\n",
       "        -1.03523389e-01,  6.95128515e-02, -1.97662190e-02,\n",
       "         5.16416244e-02],\n",
       "       [-4.66505811e-02, -1.73456559e-03,  5.43166772e-02,\n",
       "         2.23687038e-01, -2.73385078e-01,  7.03938082e-02,\n",
       "         7.06813857e-02,  8.43609199e-02,  2.69617498e-01,\n",
       "         1.74461365e-01,  1.34099811e-01,  1.85202947e-03,\n",
       "         3.42415005e-01, -1.24187157e-01,  2.09273458e-01,\n",
       "         6.03918545e-02,  8.79840273e-03, -8.17882866e-02,\n",
       "         3.45634013e-01, -7.53594637e-02, -8.21865648e-02,\n",
       "         5.38673112e-03,  4.14099813e-01,  7.42273107e-02,\n",
       "        -1.41583383e-01],\n",
       "       [ 7.78927505e-01, -6.80157065e-01,  6.66361570e-01,\n",
       "         1.69330406e+00, -4.12822676e+00, -1.91206560e-01,\n",
       "         2.38151813e+00, -1.15724695e+00,  3.47337294e+00,\n",
       "         2.87543583e+00, -1.06298888e+00,  2.44420052e+00,\n",
       "         3.36742544e+00, -7.94465914e-02,  2.42094064e+00,\n",
       "         9.62186813e-01,  1.22580397e+00,  6.13599420e-01,\n",
       "         1.06269979e+00, -7.17698991e-01, -4.54030275e-01,\n",
       "        -2.76232958e+00,  3.56611896e+00, -9.16209519e-01,\n",
       "        -4.05019194e-01],\n",
       "       [-3.22996378e-01, -7.16809750e-01, -4.05545592e-01,\n",
       "         4.20536473e-02, -2.21360755e+00,  8.97892535e-01,\n",
       "         9.44074035e-01,  5.80807626e-01,  2.23338413e+00,\n",
       "         7.35159099e-01, -1.19636691e+00,  1.69591069e+00,\n",
       "         2.76783466e+00, -2.63497960e-02,  1.70227218e+00,\n",
       "        -1.91736519e-01,  2.09414744e+00,  5.72259314e-02,\n",
       "         1.16450727e+00, -6.83605522e-02, -3.44102561e-01,\n",
       "        -8.65789533e-01,  2.45516872e+00,  7.84217477e-01,\n",
       "         2.24891841e-01],\n",
       "       [-8.50235343e-01, -6.23635590e-01, -2.01709062e-01,\n",
       "         1.76089382e+00, -3.51973081e+00,  5.72052412e-02,\n",
       "         7.20117316e-02,  1.12165928e+00,  2.07743526e+00,\n",
       "         3.37892795e+00, -6.54675305e-01,  1.01383054e+00,\n",
       "         2.79722929e+00, -9.66792703e-01,  1.52095807e+00,\n",
       "         7.80914500e-02,  7.39204586e-01, -5.95151305e-01,\n",
       "         1.65194285e+00,  1.01768804e+00,  7.54443049e-01,\n",
       "        -1.65456486e+00,  3.56370211e+00, -5.51098466e-01,\n",
       "         1.67405874e-01],\n",
       "       [-2.91595268e+00,  1.67396533e+00, -9.83101249e-01,\n",
       "         2.68895674e+00, -4.23953325e-01,  1.48070538e+00,\n",
       "        -2.82294893e+00, -1.86160594e-01,  1.17320943e+00,\n",
       "        -5.91431141e-01,  1.04542780e+00, -1.30619645e+00,\n",
       "         2.17928314e+00, -5.22774100e-01,  1.20109761e+00,\n",
       "        -2.04423356e+00, -1.51285183e+00,  1.73426342e+00,\n",
       "         2.20121050e+00,  5.01656413e-01, -1.86268055e+00,\n",
       "         2.00418901e+00,  1.48976827e+00,  2.37861490e+00,\n",
       "        -1.87001383e+00],\n",
       "       [-1.46354926e+00,  1.50809276e+00, -7.38624573e-01,\n",
       "        -1.44040501e+00, -1.37761116e+00,  3.62288564e-01,\n",
       "        -2.38521671e+00,  1.69944274e+00,  1.55637109e+00,\n",
       "         3.10330838e-01,  3.31966901e+00, -3.79963803e+00,\n",
       "         2.61957884e+00,  1.45351362e+00,  1.03182554e+00,\n",
       "        -2.43839240e+00, -6.32638693e-01,  2.12160498e-01,\n",
       "         2.98005652e+00, -7.00240791e-01, -2.58269525e+00,\n",
       "         3.54342866e+00,  3.17203021e+00,  5.76486349e-01,\n",
       "        -3.33196211e+00],\n",
       "       [-3.33520389e+00,  2.53947079e-02,  1.24436998e+00,\n",
       "         3.66145074e-01, -3.03674173e+00,  2.19885021e-01,\n",
       "        -2.62420273e+00,  1.07285881e+00, -1.73276687e+00,\n",
       "         8.97917226e-02,  3.15772414e+00, -2.11517620e+00,\n",
       "         3.29397988e+00, -1.68002650e-01, -3.71781170e-01,\n",
       "        -1.33668840e+00, -9.62701678e-01,  1.43402791e+00,\n",
       "         2.64137483e+00, -8.29065293e-02, -9.02321935e-01,\n",
       "         2.08150196e+00,  1.81510019e+00,  2.56569529e+00,\n",
       "        -2.76399708e+00],\n",
       "       [-2.49998975e+00,  8.65200639e-01,  2.14704439e-01,\n",
       "         7.64527991e-02, -1.18436646e+00,  1.08834004e+00,\n",
       "        -2.32579923e+00,  1.45447147e+00,  1.99080491e+00,\n",
       "        -7.65744373e-02,  2.32320499e+00, -3.37585926e+00,\n",
       "         2.00534821e+00,  9.77248847e-01,  1.39646888e+00,\n",
       "        -1.58542395e+00, -7.35896826e-01, -6.09305762e-02,\n",
       "         3.16990972e+00, -2.25663498e-01, -2.04611850e+00,\n",
       "         2.44441676e+00,  3.14656687e+00,  1.67616057e+00,\n",
       "        -2.48541665e+00],\n",
       "       [-5.61900914e-01, -7.45895207e-01,  2.53697425e-01,\n",
       "         7.02935755e-02, -1.45461774e+00,  1.15503740e+00,\n",
       "        -7.60933042e-01,  1.74508834e+00,  2.42750788e+00,\n",
       "        -4.41428721e-01,  8.55775177e-01, -2.15129375e+00,\n",
       "         1.52653348e+00,  1.21967685e+00,  1.59106374e+00,\n",
       "        -1.77332067e+00,  1.26035422e-01, -1.80302334e+00,\n",
       "         2.68301511e+00, -6.49991572e-01, -1.75331995e-01,\n",
       "         2.44234562e+00,  3.47473550e+00,  5.17950296e-01,\n",
       "        -1.02448344e+00],\n",
       "       [-2.91595268e+00,  1.67396533e+00, -9.83101249e-01,\n",
       "         2.68895674e+00, -4.23953325e-01,  1.48070538e+00,\n",
       "        -2.82294893e+00, -1.86160594e-01,  1.17320943e+00,\n",
       "        -5.91431141e-01,  1.04542780e+00, -1.30619645e+00,\n",
       "         2.17928314e+00, -5.22774100e-01,  1.20109761e+00,\n",
       "        -2.04423356e+00, -1.51285183e+00,  1.73426342e+00,\n",
       "         2.20121050e+00,  5.01656413e-01, -1.86268055e+00,\n",
       "         2.00418901e+00,  1.48976827e+00,  2.37861490e+00,\n",
       "        -1.87001383e+00],\n",
       "       [-9.43371356e-01,  2.35667372e+00, -3.69577885e-01,\n",
       "        -1.00031543e+00, -2.13927197e+00, -1.06680477e+00,\n",
       "        -1.74851775e+00,  6.15049958e-01,  1.38897628e-01,\n",
       "         1.72511196e+00,  1.72084749e+00, -1.83614612e+00,\n",
       "         2.73761988e+00,  8.22769463e-01,  1.24064338e+00,\n",
       "        -1.46742260e+00, -1.18044972e+00,  3.22585654e+00,\n",
       "         1.97387218e+00,  3.44584465e-01, -2.08064532e+00,\n",
       "         2.15449381e+00,  1.60427725e+00, -3.41426522e-01,\n",
       "        -2.51100159e+00],\n",
       "       [-3.33520389e+00,  2.53947079e-02,  1.24436998e+00,\n",
       "         3.66145074e-01, -3.03674173e+00,  2.19885021e-01,\n",
       "        -2.62420273e+00,  1.07285881e+00, -1.73276687e+00,\n",
       "         8.97917226e-02,  3.15772414e+00, -2.11517620e+00,\n",
       "         3.29397988e+00, -1.68002650e-01, -3.71781170e-01,\n",
       "        -1.33668840e+00, -9.62701678e-01,  1.43402791e+00,\n",
       "         2.64137483e+00, -8.29065293e-02, -9.02321935e-01,\n",
       "         2.08150196e+00,  1.81510019e+00,  2.56569529e+00,\n",
       "        -2.76399708e+00]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix = np.array(train_matrix)\n",
    "train_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 25)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit = train_matrix[4999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(twits):\n",
    "    \"\"\"\n",
    "    Does the padding as many times as required\n",
    "    \"\"\"\n",
    "    l = len(twits)\n",
    "    d= twits.shape[1]\n",
    "    padding = np.zeros(d)\n",
    "    \n",
    "    for i in range(0,max_length-l):\n",
    "        twits = np.append(twits,padding)\n",
    "        \n",
    "    return twits.reshape(max_length,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_matrix(t_matrix):\n",
    "    \"\"\"\n",
    "    Loops through all the vectorized tweets and calls the pad function on each of them.\n",
    "    \"\"\"\n",
    "    \n",
    "    padded_matrix =[]\n",
    "    for i,vectorized_tweet in enumerate(t_matrix):\n",
    "         padded_matrix.append(pad(vectorized_tweet))\n",
    "    padded_matrix = np.array(padded_matrix)\n",
    "    \n",
    "    return padded_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train_matrix = pad_matrix(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 54, 25)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df1['labels']\n",
    "labels_vector = []\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    labels_vector.append([label, 1 - label])\n",
    "labels_vector = np.array(labels_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-89176bfdc1b6>:36: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "For iter  10\n",
      "Accuracy  0.515625\n",
      "Loss  0.67319876\n",
      "__________________\n",
      "For iter  20\n",
      "Accuracy  0.6953125\n",
      "Loss  0.6200237\n",
      "__________________\n",
      "For iter  30\n",
      "Accuracy  0.8984375\n",
      "Loss  0.25687107\n",
      "__________________\n",
      "For iter  40\n",
      "Accuracy  0.9453125\n",
      "Loss  0.2739342\n",
      "__________________\n",
      "For iter  50\n",
      "Accuracy  0.890625\n",
      "Loss  0.27588338\n",
      "__________________\n",
      "For iter  60\n",
      "Accuracy  0.921875\n",
      "Loss  0.21773568\n",
      "__________________\n",
      "For iter  70\n",
      "Accuracy  0.875\n",
      "Loss  0.28757942\n",
      "__________________\n",
      "For iter  80\n",
      "Accuracy  0.90625\n",
      "Loss  0.23174456\n",
      "__________________\n",
      "For iter  90\n",
      "Accuracy  0.8828125\n",
      "Loss  0.32910788\n",
      "__________________\n",
      "For iter  100\n",
      "Accuracy  0.8984375\n",
      "Loss  0.2342968\n",
      "__________________\n",
      "For iter  110\n",
      "Accuracy  0.90625\n",
      "Loss  0.21832019\n",
      "__________________\n",
      "For iter  120\n",
      "Accuracy  0.953125\n",
      "Loss  0.10605277\n",
      "__________________\n",
      "For iter  130\n",
      "Accuracy  0.9375\n",
      "Loss  0.17138089\n",
      "__________________\n",
      "For iter  140\n",
      "Accuracy  0.9140625\n",
      "Loss  0.1827159\n",
      "__________________\n",
      "For iter  150\n",
      "Accuracy  0.8984375\n",
      "Loss  0.19850332\n",
      "__________________\n",
      "For iter  160\n",
      "Accuracy  0.921875\n",
      "Loss  0.19598018\n",
      "__________________\n",
      "For iter  170\n",
      "Accuracy  0.9375\n",
      "Loss  0.1880106\n",
      "__________________\n",
      "For iter  180\n",
      "Accuracy  0.921875\n",
      "Loss  0.22832927\n",
      "__________________\n",
      "For iter  190\n",
      "Accuracy  0.953125\n",
      "Loss  0.14577514\n",
      "__________________\n",
      "For iter  200\n",
      "Accuracy  0.9140625\n",
      "Loss  0.19032374\n",
      "__________________\n",
      "For iter  210\n",
      "Accuracy  0.9375\n",
      "Loss  0.21104302\n",
      "__________________\n",
      "For iter  220\n",
      "Accuracy  0.953125\n",
      "Loss  0.13639158\n",
      "__________________\n",
      "For iter  230\n",
      "Accuracy  0.9765625\n",
      "Loss  0.111270845\n",
      "__________________\n",
      "For iter  240\n",
      "Accuracy  0.90625\n",
      "Loss  0.24601662\n",
      "__________________\n",
      "For iter  250\n",
      "Accuracy  0.9609375\n",
      "Loss  0.077041686\n",
      "__________________\n",
      "For iter  260\n",
      "Accuracy  0.921875\n",
      "Loss  0.20864975\n",
      "__________________\n",
      "For iter  270\n",
      "Accuracy  0.90625\n",
      "Loss  0.21281944\n",
      "__________________\n",
      "For iter  280\n",
      "Accuracy  0.9609375\n",
      "Loss  0.124829926\n",
      "__________________\n",
      "For iter  290\n",
      "Accuracy  0.9375\n",
      "Loss  0.15693912\n",
      "__________________\n",
      "For iter  300\n",
      "Accuracy  0.9375\n",
      "Loss  0.15619859\n",
      "__________________\n",
      "For iter  310\n",
      "Accuracy  0.9296875\n",
      "Loss  0.17073724\n",
      "__________________\n",
      "For iter  320\n",
      "Accuracy  0.9453125\n",
      "Loss  0.15764123\n",
      "__________________\n",
      "For iter  330\n",
      "Accuracy  0.96875\n",
      "Loss  0.082879394\n",
      "__________________\n",
      "For iter  340\n",
      "Accuracy  0.9765625\n",
      "Loss  0.110232845\n",
      "__________________\n",
      "For iter  350\n",
      "Accuracy  0.9453125\n",
      "Loss  0.13107058\n",
      "__________________\n",
      "For iter  360\n",
      "Accuracy  0.9296875\n",
      "Loss  0.17159207\n",
      "__________________\n",
      "For iter  370\n",
      "Accuracy  0.9921875\n",
      "Loss  0.07394382\n",
      "__________________\n",
      "For iter  380\n",
      "Accuracy  0.9375\n",
      "Loss  0.16522725\n",
      "__________________\n",
      "For iter  390\n",
      "Accuracy  0.9609375\n",
      "Loss  0.13240746\n",
      "__________________\n",
      "For iter  400\n",
      "Accuracy  0.9453125\n",
      "Loss  0.13137984\n",
      "__________________\n",
      "For iter  410\n",
      "Accuracy  0.9765625\n",
      "Loss  0.12678492\n",
      "__________________\n",
      "For iter  420\n",
      "Accuracy  0.921875\n",
      "Loss  0.20521376\n",
      "__________________\n",
      "For iter  430\n",
      "Accuracy  0.9375\n",
      "Loss  0.15586564\n",
      "__________________\n",
      "For iter  440\n",
      "Accuracy  0.921875\n",
      "Loss  0.17338784\n",
      "__________________\n",
      "For iter  450\n",
      "Accuracy  0.9375\n",
      "Loss  0.13881803\n",
      "__________________\n",
      "For iter  460\n",
      "Accuracy  0.9609375\n",
      "Loss  0.09967558\n",
      "__________________\n",
      "For iter  470\n",
      "Accuracy  0.953125\n",
      "Loss  0.12533835\n",
      "__________________\n",
      "For iter  480\n",
      "Accuracy  0.9453125\n",
      "Loss  0.12945765\n",
      "__________________\n",
      "For iter  490\n",
      "Accuracy  0.953125\n",
      "Loss  0.15983856\n",
      "__________________\n",
      "For iter  500\n",
      "Accuracy  0.9453125\n",
      "Loss  0.13565364\n",
      "__________________\n",
      "For iter  510\n",
      "Accuracy  0.953125\n",
      "Loss  0.1407371\n",
      "__________________\n",
      "For iter  520\n",
      "Accuracy  0.9609375\n",
      "Loss  0.14147574\n",
      "__________________\n",
      "For iter  530\n",
      "Accuracy  0.9296875\n",
      "Loss  0.13577259\n",
      "__________________\n",
      "For iter  540\n",
      "Accuracy  0.9140625\n",
      "Loss  0.15578882\n",
      "__________________\n",
      "For iter  550\n",
      "Accuracy  0.9609375\n",
      "Loss  0.09182237\n",
      "__________________\n",
      "For iter  560\n",
      "Accuracy  0.9765625\n",
      "Loss  0.10617203\n",
      "__________________\n",
      "For iter  570\n",
      "Accuracy  0.9765625\n",
      "Loss  0.15113965\n",
      "__________________\n",
      "For iter  580\n",
      "Accuracy  0.9375\n",
      "Loss  0.13957109\n",
      "__________________\n",
      "For iter  590\n",
      "Accuracy  0.9609375\n",
      "Loss  0.14931852\n",
      "__________________\n",
      "For iter  600\n",
      "Accuracy  0.953125\n",
      "Loss  0.11601208\n",
      "__________________\n",
      "For iter  610\n",
      "Accuracy  0.9375\n",
      "Loss  0.13492258\n",
      "__________________\n",
      "For iter  620\n",
      "Accuracy  0.9375\n",
      "Loss  0.15357627\n",
      "__________________\n",
      "For iter  630\n",
      "Accuracy  0.9609375\n",
      "Loss  0.12314228\n",
      "__________________\n",
      "For iter  640\n",
      "Accuracy  0.9140625\n",
      "Loss  0.17192271\n",
      "__________________\n",
      "For iter  650\n",
      "Accuracy  0.9453125\n",
      "Loss  0.1394457\n",
      "__________________\n",
      "For iter  660\n",
      "Accuracy  0.90625\n",
      "Loss  0.20034346\n",
      "__________________\n",
      "For iter  670\n",
      "Accuracy  0.953125\n",
      "Loss  0.1429033\n",
      "__________________\n",
      "For iter  680\n",
      "Accuracy  0.953125\n",
      "Loss  0.11865022\n",
      "__________________\n",
      "For iter  690\n",
      "Accuracy  0.9296875\n",
      "Loss  0.16538073\n",
      "__________________\n",
      "For iter  700\n",
      "Accuracy  0.9375\n",
      "Loss  0.13278364\n",
      "__________________\n",
      "For iter  710\n",
      "Accuracy  0.9296875\n",
      "Loss  0.124966495\n",
      "__________________\n",
      "For iter  720\n",
      "Accuracy  0.984375\n",
      "Loss  0.041983724\n",
      "__________________\n",
      "For iter  730\n",
      "Accuracy  0.984375\n",
      "Loss  0.0705795\n",
      "__________________\n",
      "For iter  740\n",
      "Accuracy  0.9296875\n",
      "Loss  0.155209\n",
      "__________________\n",
      "For iter  750\n",
      "Accuracy  0.953125\n",
      "Loss  0.10363199\n",
      "__________________\n",
      "For iter  760\n",
      "Accuracy  0.9609375\n",
      "Loss  0.097234555\n",
      "__________________\n",
      "For iter  770\n",
      "Accuracy  0.96875\n",
      "Loss  0.07930671\n",
      "__________________\n",
      "For iter  780\n",
      "Accuracy  0.9453125\n",
      "Loss  0.14587802\n",
      "__________________\n",
      "For iter  790\n",
      "Accuracy  0.953125\n",
      "Loss  0.10781449\n",
      "__________________\n"
     ]
    }
   ],
   "source": [
    "#define constants\n",
    "#unrolled through 28 time steps\n",
    "time_steps=54\n",
    "#hidden LSTM units\n",
    "num_units=128\n",
    "#rows of 28 pixels\n",
    "n_input=25\n",
    "#learning rate for adam\n",
    "learning_rate=0.001\n",
    "#mnist is meant to be classified in 10 classes(0-9).\n",
    "n_classes=2\n",
    "#size of batch\n",
    "batch_size=128\n",
    "\n",
    "#weights and biases of appropriate shape to accomplish above task\n",
    "out_weights=tf.Variable(tf.random_normal([num_units,n_classes]))\n",
    "out_bias=tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "#defining placeholders\n",
    "#input image placeholder\n",
    "x=tf.placeholder(\"float\",[None,time_steps,n_input])\n",
    "#input label placeholder\n",
    "y=tf.placeholder(\"float\",[None,n_classes])\n",
    "\n",
    "#processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors\n",
    "input=tf.unstack(x ,time_steps,1)\n",
    "\n",
    "#defining the network\n",
    "lstm_layer=rnn.BasicLSTMCell(num_units,forget_bias=1)\n",
    "outputs,_=rnn.static_rnn(lstm_layer,input,dtype=\"float32\")\n",
    "\n",
    "#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\n",
    "prediction=tf.matmul(outputs[-1],out_weights)+out_bias\n",
    "\n",
    "#loss_function\n",
    "loss=tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "#optimization\n",
    "opt=tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "#model evaluation\n",
    "correct_prediction=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "#initialize variables\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    iter=1\n",
    "    while iter<800:\n",
    "        batch_x,batch_y=next_batch(batch_size, padded_train_matrix, labels_vector)\n",
    "        sess.run(opt, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        if iter %10==0:\n",
    "            acc=sess.run(accuracy,feed_dict={x:batch_x,y:batch_y})\n",
    "            los=sess.run(loss,feed_dict={x:batch_x,y:batch_y})\n",
    "            print(\"For iter \",iter)\n",
    "            print(\"Accuracy \",acc)\n",
    "            print(\"Loss \",los)\n",
    "            print(\"__________________\")\n",
    "\n",
    "        iter=iter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b488588b6fed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1058\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "sess.run(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
